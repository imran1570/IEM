{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import average_precision_score, f1_score\n",
    "\n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_training_week_data_filename_QD(week_number, simulated_org_number):\n",
    "    head_folder_name = \"C:/Users/Mimran/Google Drive/RCP 13 and RCP14/RCP13 and RCP14/July 4 Population\"\n",
    "    full_filename = \"{}/{}/org ({}).csv\".format(head_folder_name, \n",
    "                                                     week_number, \n",
    "                                                     simulated_org_number)\n",
    "    return full_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can find week 5:True\n",
      "can find week 6:True\n",
      "can find week 7:True\n",
      "can find week 8:True\n",
      "can find week 9:True\n",
      "can find week 10:True\n",
      "can find week 11:True\n",
      "can find week 12:True\n",
      "can find week 13:True\n",
      "can find week 14:True\n",
      "can find week 15:True\n",
      "can find week 16:True\n",
      "can find week 17:True\n",
      "can find week 18:True\n",
      "can find week 19:True\n",
      "can find week 20:True\n",
      "can find week 21:True\n",
      "can find week 22:True\n",
      "can find week 23:True\n",
      "can find week 24:True\n",
      "can find week 25:True\n",
      "can find week 26:True\n",
      "can find week 27:True\n",
      "can find week 28:True\n",
      "can find week 29:True\n",
      "can find week 30:True\n",
      "can find week 31:True\n",
      "can find week 32:True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "for week_number in range(5, 33):\n",
    "    print(\"can find week {}:{}\".format(week_number, \n",
    "                                       Path(get_training_week_data_filename_QD(week_number, 9)).exists()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_training_week_data_QD(week_number, simulated_org_number):\n",
    "    full_filename = get_training_week_data_filename_QD(week_number, simulated_org_number)\n",
    "    week_df = pd.read_csv(full_filename, usecols=list(range(1,67))) # Note this assumes similar order of users everywhere\n",
    "    week_df.replace([-np.inf,np.inf], np.nan, inplace=True) #(no matching of users is necessary *under this assumption*)\n",
    "    return week_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector_names = read_training_week_data_QD(50, 5).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Target',\n",
       " 'X001a',\n",
       " 'X001b',\n",
       " 'X001c',\n",
       " 'X014a',\n",
       " 'X015a',\n",
       " 'X021a',\n",
       " 'X021d',\n",
       " 'X021e',\n",
       " 'X021f',\n",
       " 'X021g',\n",
       " 'X021h',\n",
       " 'X021i',\n",
       " 'X021j',\n",
       " 'X022a',\n",
       " 'X022d',\n",
       " 'X022e',\n",
       " 'X022f',\n",
       " 'X022g',\n",
       " 'X022h',\n",
       " 'X022i',\n",
       " 'X022j',\n",
       " 'X027a',\n",
       " 'X027d',\n",
       " 'X027e',\n",
       " 'X027f',\n",
       " 'X027g',\n",
       " 'X027h',\n",
       " 'X027i',\n",
       " 'X027j',\n",
       " 'X028a',\n",
       " 'X028d',\n",
       " 'X028e',\n",
       " 'X028f',\n",
       " 'X028g',\n",
       " 'X028h',\n",
       " 'X028i',\n",
       " 'X028j',\n",
       " 'X029a',\n",
       " 'X030a',\n",
       " 'X031a',\n",
       " 'X032a',\n",
       " 'X033a',\n",
       " 'X034a',\n",
       " 'X035a',\n",
       " 'X036a',\n",
       " 'X037a',\n",
       " 'X038a',\n",
       " 'X039a',\n",
       " 'X040a',\n",
       " 'X041a',\n",
       " 'X042a',\n",
       " 'X043a',\n",
       " 'X044a',\n",
       " 'X045a',\n",
       " 'X046a',\n",
       " 'X047a',\n",
       " 'X048a',\n",
       " 'X049a',\n",
       " 'X050a',\n",
       " 'X051a',\n",
       " 'X052a',\n",
       " 'X053a',\n",
       " 'X058a',\n",
       " 'X059a',\n",
       " 'X060a']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(662017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_training_org_data(simulated_org_number, first_full_week, last_full_week):\n",
    "    all_full_week_dfs = [read_training_week_data_QD(week_number, simulated_org_number) for week_number in range(first_full_week, last_full_week + 1)]\n",
    "    return pd.concat(all_full_week_dfs).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_training_data(sample_training_data_df):\n",
    "    Ones_x = sample_training_data_df[sample_training_data_df['Target'] == 1].drop('Target', 1)\n",
    "    Ones_y = sample_training_data_df[sample_training_data_df['Target'] == 1]['Target']\n",
    "    Zeros = sample_training_data_df[sample_training_data_df['Target'] == 0]\n",
    "    Z12_x, Z3_x, Z12_y, Z3_y = train_test_split(Zeros.drop('Target', 1), Zeros['Target'],\n",
    "                                                test_size = 0.3)\n",
    "    #print(Ones_x.shape)\n",
    "    scaler = StandardScaler().fit(Z12_x)\n",
    "    Ones_x = scaler.transform(Ones_x)\n",
    "    Z12_x = scaler.transform(Z12_x)\n",
    "    Z3_x = scaler.transform(Z3_x)\n",
    "    return Z12_x, Z3_x, Z12_y.values, Z3_y.values, Ones_x, Ones_y.values, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RCP13_Algorithm_1(Z12_x, Z3_x, Z12_y, Z3_y, Ones_x, Ones_y, iter_per_k = 1):\n",
    "    k_average_areas = {}\n",
    "    for k_to_test in range(2, 65):\n",
    "        print(k_to_test)\n",
    "        k_areas = np.zeros(iter_per_k)\n",
    "        for iteration_num in range(iter_per_k):\n",
    "            n_net = MLPRegressor(hidden_layer_sizes=(k_to_test,), \n",
    "                                  activation = 'tanh', \n",
    "                                  solver = 'sgd', max_iter = 250, early_stopping = True)\n",
    "            n_net.fit(Z12_x, Z12_y)\n",
    "            model_prediction_output = n_net.predict(np.vstack([Z3_x, Ones_x]))\n",
    "            k_areas[iteration_num] = average_precision_score(np.hstack([Z3_y, Ones_y]), model_prediction_output)\n",
    "            print(\"current area is {}\".format(k_areas[iteration_num]))\n",
    "        k_average_areas[k_to_test] = k_areas.mean()\n",
    "        print(\"k {} had an average area of {}\".format(k_to_test, k_average_areas[k_to_test]))\n",
    "    return max(k_average_areas.keys(), key=(lambda key: k_average_areas[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_training_week_data_QD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fe9a6ed6a903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msome_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_training_org_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m33\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-7d063cc87579>\u001b[0m in \u001b[0;36mread_training_org_data\u001b[0;34m(simulated_org_number, first_full_week, last_full_week)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_training_org_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimulated_org_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_full_week\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_full_week\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mall_full_week_dfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mread_training_week_data_QD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweek_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimulated_org_number\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mweek_number\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_full_week\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_full_week\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_full_week_dfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7d063cc87579>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_training_org_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimulated_org_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_full_week\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_full_week\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mall_full_week_dfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mread_training_week_data_QD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweek_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimulated_org_number\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mweek_number\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_full_week\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_full_week\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_full_week_dfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_training_week_data_QD' is not defined"
     ]
    }
   ],
   "source": [
    "some_df = read_training_org_data(40, 5, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(some_df.drop('Target', 1), some_df['Target'],\n",
    "                                                test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60701, 65)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smartClassifier = RandomForestClassifier()\n",
    "smartClassifier.fit(X_train, y_train)\n",
    "y_pred = smartClassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred = y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81632653061224492"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_pred = y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25966,     0],\n",
       "       [    9,    40]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred = y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z12_x, Z3_x, Z12_y, Z3_y, Ones_x, Ones_y, some_scaler = split_training_data(some_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001372295770100097"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_df['Target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=711, splitter='best')"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_for_training_data = DecisionTreeClassifier(max_depth = 3, random_state = 711)\n",
    "tree_for_training_data.fit(some_df.drop('Target', 1), some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99944646893306888"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_for_training_data.score(some_df.drop('Target', 1), some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tree_for_training_data.predict(some_df.drop('Target', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98630136986301364"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred = y_pred, y_true = some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60504201680672265"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_pred = y_pred, y_true = some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86596,     1],\n",
       "       [   47,    72]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred = y_pred, y_true = some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dumbClassifier = DummyClassifier(random_state=711, strategy='stratified')\n",
    "dumbClassifier.fit(some_df.drop('Target', 1), some_df['Target'])\n",
    "y_pred = dumbClassifier.predict(some_df.drop('Target', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0090090090090090089"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred = y_pred, y_true = some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0084033613445378148"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_pred = y_pred, y_true = some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86472,   125],\n",
       "       [  118,     1]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred = y_pred, y_true = some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smartClassifier = RandomForestClassifier()\n",
    "smartClassifier.fit(some_df.drop('Target', 1), some_df['Target'])\n",
    "y_pred = smartClassifier.predict(some_df.drop('Target', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred = y_pred, y_true = some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98319327731092432"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_pred = y_pred, y_true = some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NBClassifer = GaussianNB()\n",
    "NBClassifer.fit(some_df.drop('Target', 1), some_df['Target'])\n",
    "y_pred = NBClassifer.predict(some_df.drop('Target', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0032446463335496431"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred = y_pred, y_true = some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88235294117647056"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_pred = y_pred, y_true = some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54341, 32256],\n",
       "       [   14,   105]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred = y_pred, y_true = some_df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_graphviz(tree_for_training_data, out_file='tree.dot', feature_names=detector_names[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ones in this organization number (20) is 45\n",
      "Number of ones in this organization number (21) is 52\n",
      "Number of ones in this organization number (22) is 42\n",
      "Number of ones in this organization number (23) is 35\n",
      "Number of ones in this organization number (24) is 46\n",
      "Number of ones in this organization number (25) is 44\n",
      "Number of ones in this organization number (26) is 40\n",
      "Number of ones in this organization number (27) is 47\n",
      "Number of ones in this organization number (28) is 46\n",
      "Number of ones in this organization number (29) is 41\n"
     ]
    }
   ],
   "source": [
    "for org_number in range(20, 30):\n",
    "    some_df = read_training_org_data(org_number, 5, 33)\n",
    "    Z12_x, Z3_x, Z12_y, Z3_y, Ones_x, Ones_y, some_scaler = split_training_data(some_df)\n",
    "    np.savetxt(\"Z12_x_{}.csv\".format(org_number), Z12_x, delimiter = \",\")\n",
    "    np.savetxt(\"Z12_y_{}.csv\".format(org_number), Z12_y, delimiter = \",\")\n",
    "    np.savetxt(\"Z3_x_{}.csv\".format(org_number), Z3_x, delimiter = \",\")\n",
    "    np.savetxt(\"Z3_y_{}.csv\".format(org_number), Z3_y, delimiter = \",\")\n",
    "    np.savetxt(\"Ones_x_{}.csv\".format(org_number), Ones_x, delimiter = \",\")\n",
    "    np.savetxt(\"Ones_y_{}.csv\".format(org_number), Ones_y, delimiter = \",\")\n",
    "    some_test_df = read_org_test_data(org_number, 34, 52)\n",
    "    T_x, T_y, T_generated_attributes = split_test_data(some_test_df, some_scaler)\n",
    "    print(\"Number of ones in this organization number ({}) is {}\".format(org_number, T_y.sum()))\n",
    "    np.savetxt(\"T_x_{}.csv\".format(org_number), T_x, delimiter = \",\")\n",
    "    np.savetxt(\"T_y_{}.csv\".format(org_number), T_y, delimiter = \",\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ones in this organization number (30) is 50\n",
      "Number of ones in this organization number (31) is 40\n",
      "Number of ones in this organization number (32) is 42\n",
      "Number of ones in this organization number (33) is 41\n",
      "Number of ones in this organization number (34) is 56\n",
      "Number of ones in this organization number (35) is 53\n",
      "Number of ones in this organization number (36) is 46\n",
      "Number of ones in this organization number (37) is 40\n",
      "Number of ones in this organization number (38) is 42\n",
      "Number of ones in this organization number (39) is 53\n"
     ]
    }
   ],
   "source": [
    "for org_number in range(30, 40):\n",
    "    some_df = read_training_org_data(org_number, 5, 33)\n",
    "    Z12_x, Z3_x, Z12_y, Z3_y, Ones_x, Ones_y, some_scaler = split_training_data(some_df)\n",
    "    np.savetxt(\"Z12_x_{}.csv\".format(org_number), Z12_x, delimiter = \",\")\n",
    "    np.savetxt(\"Z12_y_{}.csv\".format(org_number), Z12_y, delimiter = \",\")\n",
    "    np.savetxt(\"Z3_x_{}.csv\".format(org_number), Z3_x, delimiter = \",\")\n",
    "    np.savetxt(\"Z3_y_{}.csv\".format(org_number), Z3_y, delimiter = \",\")\n",
    "    np.savetxt(\"Ones_x_{}.csv\".format(org_number), Ones_x, delimiter = \",\")\n",
    "    np.savetxt(\"Ones_y_{}.csv\".format(org_number), Ones_y, delimiter = \",\")\n",
    "    some_test_df = read_org_test_data(org_number, 34, 52)\n",
    "    T_x, T_y, T_generated_attributes = split_test_data(some_test_df, some_scaler)\n",
    "    print(\"Number of ones in this organization number ({}) is {}\".format(org_number, T_y.sum()))\n",
    "    np.savetxt(\"T_x_{}.csv\".format(org_number), T_x, delimiter = \",\")\n",
    "    np.savetxt(\"T_y_{}.csv\".format(org_number), T_y, delimiter = \",\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"Z12_x.csv\", Z12_x, delimiter = \",\")\n",
    "np.savetxt(\"Z12_y.csv\", Z12_y, delimiter = \",\")\n",
    "np.savetxt(\"Z3_x.csv\", Z3_x, delimiter = \",\")\n",
    "np.savetxt(\"Z3_y.csv\", Z3_y, delimiter = \",\")\n",
    "np.savetxt(\"Ones_x.csv\", Ones_x, delimiter = \",\")\n",
    "np.savetxt(\"Ones_y.csv\", Ones_y, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mimran\\\\OneDrive - George Mason University\\\\C4I PC Backup\\\\SCITE\\\\RCPs Fifth Quarter\\\\RCP13\\\\Dev'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "current area is 0.0034713597500924697\n",
      "k 2 had an average area of 0.0034713597500924697\n",
      "3\n",
      "current area is 0.0037417372984838394\n",
      "k 3 had an average area of 0.0037417372984838394\n",
      "4\n",
      "current area is 0.00461559416491489\n",
      "k 4 had an average area of 0.00461559416491489\n",
      "5\n",
      "current area is 0.0044608715407439044\n",
      "k 5 had an average area of 0.0044608715407439044\n",
      "6\n",
      "current area is 0.0033825617455157855\n",
      "k 6 had an average area of 0.0033825617455157855\n",
      "7\n",
      "current area is 0.006033464331030584\n",
      "k 7 had an average area of 0.006033464331030584\n",
      "8\n",
      "current area is 0.005273188876478631\n",
      "k 8 had an average area of 0.005273188876478631\n",
      "9\n",
      "current area is 0.004818768643709578\n",
      "k 9 had an average area of 0.004818768643709578\n",
      "10\n",
      "current area is 0.005771357957589945\n",
      "k 10 had an average area of 0.005771357957589945\n",
      "11\n",
      "current area is 0.007996219161761055\n",
      "k 11 had an average area of 0.007996219161761055\n",
      "12\n",
      "current area is 0.0038127286188362566\n",
      "k 12 had an average area of 0.0038127286188362566\n",
      "13\n",
      "current area is 0.008714364911114264\n",
      "k 13 had an average area of 0.008714364911114264\n",
      "14\n",
      "current area is 0.007884180296781828\n",
      "k 14 had an average area of 0.007884180296781828\n",
      "15\n",
      "current area is 0.004422994129318656\n",
      "k 15 had an average area of 0.004422994129318656\n",
      "16\n",
      "current area is 0.012108172652031665\n",
      "k 16 had an average area of 0.012108172652031665\n",
      "17\n",
      "current area is 0.006139513240656391\n",
      "k 17 had an average area of 0.006139513240656391\n",
      "18\n",
      "current area is 0.0037886987473259737\n",
      "k 18 had an average area of 0.0037886987473259737\n",
      "19\n",
      "current area is 0.004662805294144412\n",
      "k 19 had an average area of 0.004662805294144412\n",
      "20\n",
      "current area is 0.0035626233432143467\n",
      "k 20 had an average area of 0.0035626233432143467\n",
      "21\n",
      "current area is 0.003909001505628801\n",
      "k 21 had an average area of 0.003909001505628801\n",
      "22\n",
      "current area is 0.01525316571382248\n",
      "k 22 had an average area of 0.01525316571382248\n",
      "23\n",
      "current area is 0.0044731037918672705\n",
      "k 23 had an average area of 0.0044731037918672705\n",
      "24\n",
      "current area is 0.005646680561129219\n",
      "k 24 had an average area of 0.005646680561129219\n",
      "25\n",
      "current area is 0.003620040398502424\n",
      "k 25 had an average area of 0.003620040398502424\n",
      "26\n",
      "current area is 0.014239200703293108\n",
      "k 26 had an average area of 0.014239200703293108\n",
      "27\n",
      "current area is 0.010358442269268093\n",
      "k 27 had an average area of 0.010358442269268093\n",
      "28\n",
      "current area is 0.0030382481393361246\n",
      "k 28 had an average area of 0.0030382481393361246\n",
      "29\n",
      "current area is 0.0060712699707720814\n",
      "k 29 had an average area of 0.0060712699707720814\n",
      "30\n",
      "current area is 0.005793758148853792\n",
      "k 30 had an average area of 0.005793758148853792\n",
      "31\n",
      "current area is 0.005496622812108433\n",
      "k 31 had an average area of 0.005496622812108433\n",
      "32\n",
      "current area is 0.003634125937578175\n",
      "k 32 had an average area of 0.003634125937578175\n",
      "33\n",
      "current area is 0.003609160581980058\n",
      "k 33 had an average area of 0.003609160581980058\n",
      "34\n",
      "current area is 0.003979465523113184\n",
      "k 34 had an average area of 0.003979465523113184\n",
      "35\n",
      "current area is 0.005128968332086811\n",
      "k 35 had an average area of 0.005128968332086811\n",
      "36\n",
      "current area is 0.008124949784455614\n",
      "k 36 had an average area of 0.008124949784455614\n",
      "37\n",
      "current area is 0.002735330735024683\n",
      "k 37 had an average area of 0.002735330735024683\n",
      "38\n",
      "current area is 0.00578039551202963\n",
      "k 38 had an average area of 0.00578039551202963\n",
      "39\n",
      "current area is 0.00553208557770393\n",
      "k 39 had an average area of 0.00553208557770393\n",
      "40\n",
      "current area is 0.006417611879261186\n",
      "k 40 had an average area of 0.006417611879261186\n",
      "41\n",
      "current area is 0.0043207823638163655\n",
      "k 41 had an average area of 0.0043207823638163655\n",
      "42\n",
      "current area is 0.0030003682304461463\n",
      "k 42 had an average area of 0.0030003682304461463\n",
      "43\n",
      "current area is 0.00362680189273118\n",
      "k 43 had an average area of 0.00362680189273118\n",
      "44\n",
      "current area is 0.006628320404987918\n",
      "k 44 had an average area of 0.006628320404987918\n",
      "45\n",
      "current area is 0.003410614608253672\n",
      "k 45 had an average area of 0.003410614608253672\n",
      "46\n",
      "current area is 0.004234466303486969\n",
      "k 46 had an average area of 0.004234466303486969\n",
      "47\n",
      "current area is 0.009736858202998825\n",
      "k 47 had an average area of 0.009736858202998825\n",
      "48\n",
      "current area is 0.004596045260770122\n",
      "k 48 had an average area of 0.004596045260770122\n",
      "49\n",
      "current area is 0.004595277320799451\n",
      "k 49 had an average area of 0.004595277320799451\n",
      "50\n",
      "current area is 0.0065067606361371945\n",
      "k 50 had an average area of 0.0065067606361371945\n",
      "51\n",
      "current area is 0.005841082981866447\n",
      "k 51 had an average area of 0.005841082981866447\n",
      "52\n",
      "current area is 0.007391536054516304\n",
      "k 52 had an average area of 0.007391536054516304\n",
      "53\n",
      "current area is 0.004713064728583496\n",
      "k 53 had an average area of 0.004713064728583496\n",
      "54\n",
      "current area is 0.0036363021645087167\n",
      "k 54 had an average area of 0.0036363021645087167\n",
      "55\n",
      "current area is 0.004252321112933156\n",
      "k 55 had an average area of 0.004252321112933156\n",
      "56\n",
      "current area is 0.0035248708001759353\n",
      "k 56 had an average area of 0.0035248708001759353\n",
      "57\n",
      "current area is 0.0032437206065868015\n",
      "k 57 had an average area of 0.0032437206065868015\n",
      "58\n",
      "current area is 0.003333352896840047\n",
      "k 58 had an average area of 0.003333352896840047\n",
      "59\n",
      "current area is 0.005843717483995974\n",
      "k 59 had an average area of 0.005843717483995974\n",
      "60\n",
      "current area is 0.005132076647731142\n",
      "k 60 had an average area of 0.005132076647731142\n",
      "61\n",
      "current area is 0.004044550711648939\n",
      "k 61 had an average area of 0.004044550711648939\n",
      "62\n",
      "current area is 0.004488390143436323\n",
      "k 62 had an average area of 0.004488390143436323\n",
      "63\n",
      "current area is 0.011969647566321878\n",
      "k 63 had an average area of 0.011969647566321878\n",
      "64\n",
      "current area is 0.007558880614011255\n",
      "k 64 had an average area of 0.007558880614011255\n"
     ]
    }
   ],
   "source": [
    "best_k = RCP13_Algorithm_1(Z12_x, Z3_x, Z12_y, Z3_y, Ones_x, Ones_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_testing_week_data_filename_QD(week_number, simulated_org_number):\n",
    "    head_folder_name = \"C:/Users/Mimran/Google Drive/RCP 13 and RCP14/RCP13 and RCP14/July 7 Testing Data 50 Organizations\"\n",
    "    full_filename = \"{}/{}/org ({}).csv\".format(head_folder_name, \n",
    "                                                     week_number, \n",
    "                                                     simulated_org_number)\n",
    "    return full_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Mimran/Google Drive/RCP 13 and RCP14/RCP13 and RCP14/July 7 Testing Data 50 Organizations/34/org (4).csv'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_testing_week_data_filename_QD(34, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_testing_week_data_QD(week_number, simulated_org_number):\n",
    "    full_filename = get_testing_week_data_filename_QD(week_number, simulated_org_number)\n",
    "    week_df = pd.read_csv(full_filename, usecols=list(range(1,67))) # Note this assumes similar order of users everywhere\n",
    "    week_df.replace([-np.inf,np.inf], np.nan, inplace=True) #(no matching of users is necessary *under this assumption*)\n",
    "    return week_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_org_test_data(simulated_org_number, first_week, last_week):\n",
    "    all_full_week_dfs = []\n",
    "    for current_week in range(first_week, last_week + 1):\n",
    "        current_week_df = read_testing_week_data_QD(current_week, simulated_org_number)\n",
    "        detector_string = 'X021f'\n",
    "        current_week_df['trait_4'] = (current_week_df['{}'.format(detector_string)] > np.percentile(current_week_df['{}'.format(detector_string)], 90))\n",
    "        detector_string = 'X021h'\n",
    "        current_week_df['trait_6'] = (current_week_df['{}'.format(detector_string)] > np.percentile(current_week_df['{}'.format(detector_string)], 90))\n",
    "        detector_string = 'X022f'\n",
    "        current_week_df['trait_8'] = (current_week_df['{}'.format(detector_string)] > np.percentile(current_week_df['{}'.format(detector_string)], 90))\n",
    "        detector_string = 'X022h'\n",
    "        current_week_df['trait_10'] = (current_week_df['{}'.format(detector_string)] > np.percentile(current_week_df['{}'.format(detector_string)], 90))\n",
    "        detector_string = 'X027f'\n",
    "        current_week_df['trait_12'] = (current_week_df['{}'.format(detector_string)] > np.percentile(current_week_df['{}'.format(detector_string)], 90))\n",
    "        detector_string = 'X027h'\n",
    "        current_week_df['trait_14'] = (current_week_df['{}'.format(detector_string)] > np.percentile(current_week_df['{}'.format(detector_string)], 90))\n",
    "        detector_string = 'X028f'\n",
    "        current_week_df['trait_16'] = (current_week_df['{}'.format(detector_string)] > np.percentile(current_week_df['{}'.format(detector_string)], 90))\n",
    "        detector_string = 'X028h'\n",
    "        current_week_df['trait_18'] = (current_week_df['{}'.format(detector_string)] > np.percentile(current_week_df['{}'.format(detector_string)], 90))\n",
    "        detector_string = 'X058a'\n",
    "        current_week_df['trait_20'] = (current_week_df['{}'.format(detector_string)])\n",
    "        all_full_week_dfs.append(current_week_df)\n",
    "    return pd.concat(all_full_week_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_trait_names = [\"trait_\" + str(trait_num) for trait_num in range(4, 21, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_test_data(sample_test_data_df, scaler_from_training_data):\n",
    "    T_x, T_y, T_generated_attributes = (sample_test_data_df[detector_names[1:]], \n",
    "                                        sample_test_data_df['Target'], \n",
    "                                        sample_test_data_df[all_trait_names])\n",
    "    T_x = scaler_from_training_data.transform(T_x)\n",
    "    return T_x, T_y.values, T_generated_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mse(true_detector_values, predicted_detector_values):\n",
    "    return mean_squared_error(true_detector_values, predicted_detector_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_using_mse(true_detector_values, predicted_detector_values, test_cutoff):\n",
    "    return (mean_squared_error(true_detector_values, predicted_detector_values) > test_cutoff).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_f1_score_using_threshold(actual_y, true_detector_values, predicted_detector_values, test_cutoff):\n",
    "    return f1_score(actual_y, predict_using_mse(true_detector_values, predicted_detector_values, test_cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RCP13_Algorithm_2(Z12_x, Z3_x, Z12_y, Z3_y, Ones_x, Ones_y, T_x, T_y,  \n",
    "                      T_generated_attributes, chosen_k, num_iterations = 100):\n",
    "    answer_dict = {\"Answer_\" + str(answer_num) : np.zeros(num_iterations) for answer_num in range(1, 22)}\n",
    "    for iteration_num in range(num_iterations):\n",
    "        n_net = MLPRegressor(hidden_layer_sizes=(chosen_k,), \n",
    "                                  activation = 'tanh', \n",
    "                                  solver = 'sgd', max_iter = 250, early_stopping = True)\n",
    "        n_net.fit(Z12_x, Z12_y)\n",
    "        model_prediction_output = n_net.predict(np.vstack([Z3_x, Ones_x]))\n",
    "        def func_to_min(x):\n",
    "            return -calc_f1_score_using_threshold(x, np.hstack([Z3_y, Ones_y]), model_prediction_output)\n",
    "        chosen_tau = minimize_scalar(func_to_min, bounds = (0, 1), method = 'bounded').x\n",
    "        print(\"optimized cutoff is {}\".format(chosen_tau))\n",
    "        prediction_output_for_test_data = n_net.predict(T_x)\n",
    "        T_labels = (prediction_output_for_test_data > chosen_tau).astype(int)\n",
    "        answer_dict[\"Answer_1\"][iteration_num] = (T_y & T_labels).sum() / T_y.sum()\n",
    "        answer_dict[\"Answer_2\"][iteration_num] = (T_y & T_labels).sum() / T_labels.sum()\n",
    "        answer_dict[\"Answer_3\"][iteration_num] = (T_y & T_labels).sum() / (T_y ^ 1).sum()\n",
    "        answer_dict[\"Answer_4\"][iteration_num] = (T_generated_attributes['trait_4'].values & T_labels).mean() / (T_labels).mean()\n",
    "        answer_dict[\"Answer_5\"][iteration_num] = (T_generated_attributes['trait_4'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_4'])\n",
    "        answer_dict[\"Answer_6\"][iteration_num] = (T_generated_attributes['trait_6'].values & T_labels).mean() / (T_labels).mean()\n",
    "        answer_dict[\"Answer_7\"][iteration_num] = (T_generated_attributes['trait_6'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_6'])\n",
    "        answer_dict[\"Answer_8\"][iteration_num] = (T_generated_attributes['trait_8'].values & T_labels).mean() / (T_labels).mean()\n",
    "        answer_dict[\"Answer_9\"][iteration_num] = (T_generated_attributes['trait_8'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_8'])\n",
    "        answer_dict[\"Answer_10\"][iteration_num] = (T_generated_attributes['trait_10'].values & T_labels).mean() / (T_labels).mean()\n",
    "        answer_dict[\"Answer_11\"][iteration_num] = (T_generated_attributes['trait_10'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_10'])\n",
    "        answer_dict[\"Answer_12\"][iteration_num] = (T_generated_attributes['trait_12'].values & T_labels).mean() / (T_labels).mean()\n",
    "        answer_dict[\"Answer_13\"][iteration_num] = (T_generated_attributes['trait_12'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_12'])\n",
    "        answer_dict[\"Answer_14\"][iteration_num] = (T_generated_attributes['trait_14'].values & T_labels).mean() / (T_labels).mean()\n",
    "        answer_dict[\"Answer_15\"][iteration_num] = (T_generated_attributes['trait_14'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_14'])\n",
    "        answer_dict[\"Answer_16\"][iteration_num] = (T_generated_attributes['trait_16'].values & T_labels).mean() / (T_labels).mean()\n",
    "        answer_dict[\"Answer_17\"][iteration_num] = (T_generated_attributes['trait_16'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_16'])\n",
    "        answer_dict[\"Answer_18\"][iteration_num] = (T_generated_attributes['trait_18'].values & T_labels).mean() / (T_labels).mean()\n",
    "        answer_dict[\"Answer_19\"][iteration_num] = (T_generated_attributes['trait_18'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_18'])\n",
    "        answer_dict[\"Answer_20\"][iteration_num] = (T_generated_attributes['trait_20'].values & T_labels).mean() / (T_labels).mean()\n",
    "        answer_dict[\"Answer_21\"][iteration_num] = (T_generated_attributes['trait_20'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_20'])\n",
    "    return answer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "some_test_df = read_org_test_data(9, 34, 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_x, T_y, T_generated_attributes = split_test_data(some_test_df, some_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99925224750607544"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smartClassifier.score(T_x, T_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00073174301185423675"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred = tree_for_training_data.predict(T_x), y_true=T_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22727272727272727"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_pred = tree_for_training_data.predict(T_x), y_true=T_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23224512686300836"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_for_training_data.predict(T_x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smartClassifier.predict(T_x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"T_x.csv\", T_x, delimiter = \",\")\n",
    "np.savetxt(\"T_y.csv\", T_y, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T_labels = pd.read_csv(\"T_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T_labels = (T_labels.values).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_labels.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer_dict = {\"Answer_\" + str(answer_num) : np.zeros(1) for answer_num in range(1, 22)}\n",
    "iteration_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer_dict[\"Answer_1\"][iteration_num] = (T_y & T_labels).sum() / T_y.sum()\n",
    "answer_dict[\"Answer_2\"][iteration_num] = (T_y & T_labels).sum() / T_labels.sum()\n",
    "answer_dict[\"Answer_3\"][iteration_num] = (T_y & T_labels).sum() / (T_y ^ 1).sum()\n",
    "answer_dict[\"Answer_4\"][iteration_num] = (T_generated_attributes['trait_4'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_5\"][iteration_num] = (T_generated_attributes['trait_4'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_4'])\n",
    "answer_dict[\"Answer_6\"][iteration_num] = (T_generated_attributes['trait_6'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_7\"][iteration_num] = (T_generated_attributes['trait_6'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_6'])\n",
    "answer_dict[\"Answer_8\"][iteration_num] = (T_generated_attributes['trait_8'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_9\"][iteration_num] = (T_generated_attributes['trait_8'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_8'])\n",
    "answer_dict[\"Answer_10\"][iteration_num] = (T_generated_attributes['trait_10'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_11\"][iteration_num] = (T_generated_attributes['trait_10'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_10'])\n",
    "answer_dict[\"Answer_12\"][iteration_num] = (T_generated_attributes['trait_12'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_13\"][iteration_num] = (T_generated_attributes['trait_12'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_12'])\n",
    "answer_dict[\"Answer_14\"][iteration_num] = (T_generated_attributes['trait_14'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_15\"][iteration_num] = (T_generated_attributes['trait_14'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_14'])\n",
    "answer_dict[\"Answer_16\"][iteration_num] = (T_generated_attributes['trait_16'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_17\"][iteration_num] = (T_generated_attributes['trait_16'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_16'])\n",
    "answer_dict[\"Answer_18\"][iteration_num] = (T_generated_attributes['trait_18'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_19\"][iteration_num] = (T_generated_attributes['trait_18'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_18'])\n",
    "answer_dict[\"Answer_20\"][iteration_num] = (T_generated_attributes['trait_20'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_21\"][iteration_num] = (T_generated_attributes['trait_20'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Answer_1': array([ 0.]),\n",
       " 'Answer_10': array([ 0.58064516]),\n",
       " 'Answer_11': array([ 0.00617072]),\n",
       " 'Answer_12': array([ 0.48387097]),\n",
       " 'Answer_13': array([ 0.00588813]),\n",
       " 'Answer_14': array([ 0.51612903]),\n",
       " 'Answer_15': array([ 0.00560224]),\n",
       " 'Answer_16': array([ 0.5]),\n",
       " 'Answer_17': array([ 0.00598918]),\n",
       " 'Answer_18': array([ 0.56451613]),\n",
       " 'Answer_19': array([ 0.00622444]),\n",
       " 'Answer_2': array([ 0.]),\n",
       " 'Answer_20': array([ 0.08064516]),\n",
       " 'Answer_21': array([ 0.01010101]),\n",
       " 'Answer_3': array([ 0.]),\n",
       " 'Answer_4': array([ 0.51612903]),\n",
       " 'Answer_5': array([ 0.00562291]),\n",
       " 'Answer_6': array([ 0.51612903]),\n",
       " 'Answer_7': array([ 0.00549828]),\n",
       " 'Answer_8': array([ 0.53225806]),\n",
       " 'Answer_9': array([ 0.00590129])}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_labels_dict = {}\n",
    "T_labels_dict[20] = pd.read_csv(\"T_labels20.csv\").values.T\n",
    "some_test_df = read_org_test_data(20, 34, 52)\n",
    "T_x, T_y, T_generated_attributes = split_test_data(some_test_df, some_scaler)\n",
    "answer_dict = {\"Answer_\" + str(answer_num) : np.zeros(1) for answer_num in range(1, 22)}\n",
    "T_labels = T_labels_dict[20]\n",
    "iteration_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer_dict[\"Answer_1\"][iteration_num] = (T_y & T_labels).sum() / T_y.sum()\n",
    "answer_dict[\"Answer_2\"][iteration_num] = (T_y & T_labels).sum() / T_labels.sum()\n",
    "answer_dict[\"Answer_3\"][iteration_num] = (T_y & T_labels).sum() / (T_y ^ 1).sum()\n",
    "answer_dict[\"Answer_4\"][iteration_num] = (T_generated_attributes['trait_4'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_5\"][iteration_num] = (T_generated_attributes['trait_4'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_4'])\n",
    "answer_dict[\"Answer_6\"][iteration_num] = (T_generated_attributes['trait_6'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_7\"][iteration_num] = (T_generated_attributes['trait_6'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_6'])\n",
    "answer_dict[\"Answer_8\"][iteration_num] = (T_generated_attributes['trait_8'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_9\"][iteration_num] = (T_generated_attributes['trait_8'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_8'])\n",
    "answer_dict[\"Answer_10\"][iteration_num] = (T_generated_attributes['trait_10'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_11\"][iteration_num] = (T_generated_attributes['trait_10'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_10'])\n",
    "answer_dict[\"Answer_12\"][iteration_num] = (T_generated_attributes['trait_12'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_13\"][iteration_num] = (T_generated_attributes['trait_12'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_12'])\n",
    "answer_dict[\"Answer_14\"][iteration_num] = (T_generated_attributes['trait_14'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_15\"][iteration_num] = (T_generated_attributes['trait_14'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_14'])\n",
    "answer_dict[\"Answer_16\"][iteration_num] = (T_generated_attributes['trait_16'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_17\"][iteration_num] = (T_generated_attributes['trait_16'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_16'])\n",
    "answer_dict[\"Answer_18\"][iteration_num] = (T_generated_attributes['trait_18'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_19\"][iteration_num] = (T_generated_attributes['trait_18'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_18'])\n",
    "answer_dict[\"Answer_20\"][iteration_num] = (T_generated_attributes['trait_20'].values & T_labels).mean() / (T_labels).mean()\n",
    "answer_dict[\"Answer_21\"][iteration_num] = (T_generated_attributes['trait_20'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Answer_1': array([ 0.]),\n",
       " 'Answer_10': array([ 0.12837838]),\n",
       " 'Answer_11': array([ 0.00325621]),\n",
       " 'Answer_12': array([ 0.08108108]),\n",
       " 'Answer_13': array([ 0.00242915]),\n",
       " 'Answer_14': array([ 0.12162162]),\n",
       " 'Answer_15': array([ 0.00320171]),\n",
       " 'Answer_16': array([ 0.10810811]),\n",
       " 'Answer_17': array([ 0.00317965]),\n",
       " 'Answer_18': array([ 0.12162162]),\n",
       " 'Answer_19': array([ 0.00318528]),\n",
       " 'Answer_2': array([ 0.]),\n",
       " 'Answer_20': array([ 0.05405405]),\n",
       " 'Answer_21': array([ 0.01410935]),\n",
       " 'Answer_3': array([ 0.]),\n",
       " 'Answer_4': array([ 0.10135135]),\n",
       " 'Answer_5': array([ 0.0026325]),\n",
       " 'Answer_6': array([ 0.12162162]),\n",
       " 'Answer_7': array([ 0.00309332]),\n",
       " 'Answer_8': array([ 0.08783784]),\n",
       " 'Answer_9': array([ 0.00230906])}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(answer_dict).to_csv(\"Answers_20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer_1 \t 0.000\n",
      "Answer_2 \t 0.000\n",
      "Answer_3 \t 0.000\n",
      "Answer_4 \t 0.101\n",
      "Answer_5 \t 0.003\n",
      "Answer_6 \t 0.122\n",
      "Answer_7 \t 0.003\n",
      "Answer_8 \t 0.088\n",
      "Answer_9 \t 0.002\n",
      "Answer_10 \t 0.128\n",
      "Answer_11 \t 0.003\n",
      "Answer_12 \t 0.081\n",
      "Answer_13 \t 0.002\n",
      "Answer_14 \t 0.122\n",
      "Answer_15 \t 0.003\n",
      "Answer_16 \t 0.108\n",
      "Answer_17 \t 0.003\n",
      "Answer_18 \t 0.122\n",
      "Answer_19 \t 0.003\n",
      "Answer_20 \t 0.054\n",
      "Answer_21 \t 0.014\n"
     ]
    }
   ],
   "source": [
    "for answer_num in range(1, 22):\n",
    "    print(\"{} \\t {:.3f}\".format(\"Answer_{}\".format(answer_num), answer_dict[\"Answer_{}\".format(answer_num)][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "successes = [20, 21, 24, 27, 28, 30, 34, 35, 36, 39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T_labels_dict = {}\n",
    "answer_dicts = {}\n",
    "for org_number in [39]:\n",
    "    T_labels_dict[org_number] = pd.read_csv(\"T_labels{}.csv\".format(org_number)).values.T\n",
    "    some_test_df = read_org_test_data(org_number, 34, 52)\n",
    "    T_x, T_y, T_generated_attributes = split_test_data(some_test_df, some_scaler)\n",
    "    answer_dict = {\"Answer_\" + str(answer_num) : np.zeros(1) for answer_num in range(1, 22)}\n",
    "    T_labels = T_labels_dict[org_number]\n",
    "    iteration_num = 0\n",
    "    answer_dict[\"Answer_1\"][iteration_num] = (T_y & T_labels).sum() / T_y.sum()\n",
    "    answer_dict[\"Answer_2\"][iteration_num] = (T_y & T_labels).sum() / T_labels.sum()\n",
    "    answer_dict[\"Answer_3\"][iteration_num] = (T_y & T_labels).sum() / (T_y ^ 1).sum()\n",
    "    answer_dict[\"Answer_4\"][iteration_num] = (T_generated_attributes['trait_4'].values & T_labels).mean() / (T_labels).mean()\n",
    "    answer_dict[\"Answer_5\"][iteration_num] = (T_generated_attributes['trait_4'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_4'])\n",
    "    answer_dict[\"Answer_6\"][iteration_num] = (T_generated_attributes['trait_6'].values & T_labels).mean() / (T_labels).mean()\n",
    "    answer_dict[\"Answer_7\"][iteration_num] = (T_generated_attributes['trait_6'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_6'])\n",
    "    answer_dict[\"Answer_8\"][iteration_num] = (T_generated_attributes['trait_8'].values & T_labels).mean() / (T_labels).mean()\n",
    "    answer_dict[\"Answer_9\"][iteration_num] = (T_generated_attributes['trait_8'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_8'])\n",
    "    answer_dict[\"Answer_10\"][iteration_num] = (T_generated_attributes['trait_10'].values & T_labels).mean() / (T_labels).mean()\n",
    "    answer_dict[\"Answer_11\"][iteration_num] = (T_generated_attributes['trait_10'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_10'])\n",
    "    answer_dict[\"Answer_12\"][iteration_num] = (T_generated_attributes['trait_12'].values & T_labels).mean() / (T_labels).mean()\n",
    "    answer_dict[\"Answer_13\"][iteration_num] = (T_generated_attributes['trait_12'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_12'])\n",
    "    answer_dict[\"Answer_14\"][iteration_num] = (T_generated_attributes['trait_14'].values & T_labels).mean() / (T_labels).mean()\n",
    "    answer_dict[\"Answer_15\"][iteration_num] = (T_generated_attributes['trait_14'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_14'])\n",
    "    answer_dict[\"Answer_16\"][iteration_num] = (T_generated_attributes['trait_16'].values & T_labels).mean() / (T_labels).mean()\n",
    "    answer_dict[\"Answer_17\"][iteration_num] = (T_generated_attributes['trait_16'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_16'])\n",
    "    answer_dict[\"Answer_18\"][iteration_num] = (T_generated_attributes['trait_18'].values & T_labels).mean() / (T_labels).mean()\n",
    "    answer_dict[\"Answer_19\"][iteration_num] = (T_generated_attributes['trait_18'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_18'])\n",
    "    answer_dict[\"Answer_20\"][iteration_num] = (T_generated_attributes['trait_20'].values & T_labels).mean() / (T_labels).mean()\n",
    "    answer_dict[\"Answer_21\"][iteration_num] = (T_generated_attributes['trait_20'].values & T_labels).mean() / np.mean(T_generated_attributes['trait_20'])\n",
    "    for answer_num in range(1, 22):\n",
    "        answer_dict[\"Answer_{}\".format(answer_num)] = answer_dict[\"Answer_{}\".format(answer_num)][0]\n",
    "    answer_dicts[org_number] = answer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer_1</th>\n",
       "      <th>Answer_10</th>\n",
       "      <th>Answer_11</th>\n",
       "      <th>Answer_12</th>\n",
       "      <th>Answer_13</th>\n",
       "      <th>Answer_14</th>\n",
       "      <th>Answer_15</th>\n",
       "      <th>Answer_16</th>\n",
       "      <th>Answer_17</th>\n",
       "      <th>Answer_18</th>\n",
       "      <th>...</th>\n",
       "      <th>Answer_2</th>\n",
       "      <th>Answer_20</th>\n",
       "      <th>Answer_21</th>\n",
       "      <th>Answer_3</th>\n",
       "      <th>Answer_4</th>\n",
       "      <th>Answer_5</th>\n",
       "      <th>Answer_6</th>\n",
       "      <th>Answer_7</th>\n",
       "      <th>Answer_8</th>\n",
       "      <th>Answer_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.08545</td>\n",
       "      <td>0.012774</td>\n",
       "      <td>0.073903</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.099307</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>0.06582</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.08545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>0.360277</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.084296</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.095843</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.076212</td>\n",
       "      <td>0.011665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Answer_1  Answer_10  Answer_11  Answer_12  Answer_13  Answer_14  \\\n",
       "39  0.226415    0.08545   0.012774   0.073903   0.012942   0.099307   \n",
       "\n",
       "    Answer_15  Answer_16  Answer_17  Answer_18    ...     Answer_2  Answer_20  \\\n",
       "39   0.015019    0.06582     0.0114    0.08545    ...     0.013857   0.360277   \n",
       "\n",
       "    Answer_21  Answer_3  Answer_4  Answer_5  Answer_6  Answer_7  Answer_8  \\\n",
       "39        0.6  0.000204  0.084296  0.012843  0.095843    0.0142  0.076212   \n",
       "\n",
       "    Answer_9  \n",
       "39  0.011665  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(answer_dicts).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pd.DataFrame(answer_dicts).T).to_csv(\"Attempt_at_answer_39.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
